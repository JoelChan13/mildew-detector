{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Model and Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Develop an ML model that classifies leaf images into these two categories; healthy or containing powdery mildew (Business Requirement 2).\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cherryleaves_dataset/cherry-leaves/test\n",
        "* inputs/cherryleaves_dataset/cherry-leaves/train\n",
        "* inputs/cherryleaves_dataset/cherry-leaves/validation\n",
        "* image shape embeddings.\n",
        "\n",
        "```plaintext\n",
        "├── inputs\n",
        "│ └── cherryleaves_dataset\n",
        "│ └── cherry-leaves\n",
        "│   ├── test\n",
        "│   │ ├── healthy\n",
        "│   │ └── powdery_mildew\n",
        "│   ├── train\n",
        "│   │ ├── healthy\n",
        "│   │ └── powdery_mildew\n",
        "│   └── validation\n",
        "│   │ ├── healthy\n",
        "│   │ └── powdery_mildew\n",
        "└── ...\n",
        "``` \n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Image distribution plot in train, validation, and test set\n",
        "* Image augementation for each set\n",
        "* Class indices to change prediction inference in labels\n",
        "* Creation of an ML model\n",
        "* Display ML model summary\n",
        "* Train ML model\n",
        "* Save ML model\n",
        "* Create Learning Curve Plot for model performance\n",
        "* Model Evaluation on pickle file; determine accuracy, plot ROC curve, and calculate classification report \n",
        "* Plot Confusion Matrix\n",
        "* Prediction on the random image file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import seaborn as sns \n",
        "import tensorflow as tf\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Set Working Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "cwd = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('/workspace/mildew-detector')\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "## Set Input Directories\n",
        "Set train, validation and test paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/cherryleaves_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train' \n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Label Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "print('Label for the images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Image Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Images Distribution\n",
        "\n",
        "These plots will give you a comprehensive view of your dataset's distribution across different labels and sets, which is essential for understanding data balance and preparing for model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Count Number of Images per Set & Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "\n",
        "df_freq = pd.DataFrame([])\n",
        "for folder in ['train', 'test', 'validation']:\n",
        "    for label in labels:\n",
        "        df_freq = df_freq.append(\n",
        "            pd.Series(data={'Set': folder,\n",
        "                            'Label': label,\n",
        "                            'Count': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))}\n",
        "                      ),\n",
        "            ignore_index=True\n",
        "        )\n",
        "\n",
        "        print(\n",
        "            f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
        "\n",
        "print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Label Distribution - Bar Chart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig = px.bar(df_freq, \n",
        "            x=\"Set\", \n",
        "            y=\"Count\", \n",
        "            color='Label', \n",
        "            title=\"Cherry Leaves Dataset\", \n",
        "            text_auto=True)\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=800, \n",
        "    height=500, \n",
        "    )\n",
        "fig.show()\n",
        "fig.write_image(f'{file_path}/number_leaves_sets.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(data=df_freq, x='Set', y='Count', estimator=sum, ci=None)\n",
        "plt.title('Total Images per Set')\n",
        "plt.xlabel('Set')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "plt.savefig(f'{file_path}/sets_distribution_bar.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Image Data Augmentation\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Batch Size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 18"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment Training Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Augmented Training Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "for _ in range(3):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    img, label = train_set.next()\n",
        "    print(img.shape)  \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment Validation Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Augmented Validation Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    img, label = validation_set.next()\n",
        "    print(img.shape)  \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment Test Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Augmented Test Image Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    plt.figure(figsize=(2, 2))\n",
        "    img, label = test_set.next()\n",
        "    print(img.shape)  \n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam, Adagrad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    ### input layer\n",
        "    model.add(Conv2D(32, (3, 3), input_shape=image_shape, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    ### convolutional layers\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))      \n",
        "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    ### fully connected layer\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(.2))\n",
        "\n",
        "    ### output\n",
        "    model.add(Dense(2, activation='softmax')) \n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', \n",
        "                  optimizer='adagrad',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Callbacks\n",
        "Callbacks are a powerful feature in machine learning, particularly when training models using libraries like TensorFlow and Keras. They provide a mechanism to control and customize the training process, allowing users to take specific actions at various stages of the training lifecycle."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### EarlyStopping & ModelCheckPoint\n",
        "* EarlyStopping is used to monitor the val_accuracy (validation accuracy). \n",
        "* If the validation accuracy does not improve for a set number of epochs (patience=2 in your case), training will stop. \n",
        "* This prevents overfitting, where the model becomes too specialized on the training data and performs poorly on unseen data (like validation or test sets).\n",
        "---\n",
        "* ModelCheckPoint monitors the val_accuracy and saves the model with the highest validation accuracy to the file path specified (outputs/v1/powdery_mildew_model.h5)\n",
        "* This ensures that you have a copy of the best-performing model, which is crucial if you want to avoid retraining the model from scratch or in case of any interruptions during training. \n",
        "* Saving only the best model also helps manage storage efficiently, especially if the training process runs for many epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_accuracy',mode='max',verbose=1, patience=2)\n",
        "m_checkpoint = ModelCheckpoint(filepath='outputs/v1/powdery_mildew_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit Model for Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          batch_size=batch_size,\n",
        "          epochs=32,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop, m_checkpoint],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/powdery_mildew_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Learning Curve A - Training, Validation, Loss & Accuracy Over Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "plt.figure(figsize=(5, 4))\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Learning Curve B - Loss & Accuracy Over Training Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pd.DataFrame(model.history.history).plot(figsize=(8,5))\n",
        "plt.savefig(f'{file_path}/model_loss_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Learning Curve C - Loss & Accuracy Metrics of Model's Training Process Over Multiple Epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['val_loss'], name=\"val_loss\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['loss'], name=\"loss\"),\n",
        "    secondary_y=False,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['val_accuracy'], name=\"val accuracy\"),\n",
        "    secondary_y=True,\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter( y=model.history.history['accuracy'], name=\"accuracy\"),\n",
        "    secondary_y=True,\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    title_text=\"Loss/Accuracy of LSTM Model\"\n",
        ")\n",
        "\n",
        "fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "fig.update_yaxes(title_text=\"<b>primary</b> Loss\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"<b>secondary</b> Accuracy\", secondary_y=True)\n",
        "\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=800, \n",
        "    height=500, \n",
        "    )\n",
        "\n",
        "fig.show()\n",
        "fig.write_image(f'{file_path}/model_history.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sklearn\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('outputs/v1/powdery_mildew_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate Model Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set, batch_size=batch_size)\n",
        "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
        "print(\"Model Loss: \",evaluation[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set Accuracy Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set.reset()\n",
        "\n",
        "x_true, y_true = next(test_set)\n",
        "preds = np.argmax(model.predict(test_set), axis=1)\n",
        "y_pred = np.rint(preds)\n",
        "y_true = test_set.labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_true, y_pred) # fpr: False Positive Rate, tpr: True Positive Rate\n",
        "roc_auc = auc(fpr, tpr) # Calculate the Area Under the Curve (AUC) for the ROC curve\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "lw = 2\n",
        "\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, label=\"Random classifier\", linestyle='--')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "plt.xlabel('False Positive Rate (Specificity)')\n",
        "plt.ylabel('True Positive Rate (Sensitivity)')\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.savefig(f'{file_path}/roccurve.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "print('Area Under ROC-Curve: ', roc_auc_score(y_true, y_pred))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate the confusion matrix based on the true and predicted labels\n",
        "cm = confusion_matrix(y_true,y_pred)\n",
        "\n",
        "# Retrieve the class names from the test set to label the axes of the confusion matrix\n",
        "classes=list(test_set.class_indices.keys()) \n",
        "\n",
        "# Determine the number of classes\n",
        "length=len(classes)\n",
        "\n",
        "# Create a new figure for the confusion matrix plot with a specified figure size\n",
        "plt.figure(figsize=(8, 5))\n",
        "\n",
        "# Create a heatmap to visualise the confusion matrix\n",
        "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
        "\n",
        "# Set the tick marks for the x-axis\n",
        "plt.xticks(np.arange(length)+.5, classes, rotation= 0, fontsize=8)\n",
        "\n",
        "# Set the tick marks for the y-axis\n",
        "plt.yticks(np.arange(length)+.3, classes, rotation=90, fontsize=8)\n",
        "\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification Report - A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def warn(*args, **kwargs):\n",
        "    pass\n",
        "import warnings\n",
        "warnings.warn = warn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('Classification Report:\\n----------------------\\n')\n",
        "print(classification_report(y_true, y_pred, target_names=labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification Report - B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "clf_report = classification_report(y_true, y_pred, target_names=labels, output_dict=True)\n",
        "fig, ax = plt.subplots(figsize=(8,5))\n",
        "sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True, cmap=\"Blues\", cbar=False, linewidths=1)\n",
        "plt.title('Classification Report')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Classification Report - C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import pathlib\n",
        "\n",
        "def plot_classification_report(y_test, y_pred, title='Classification Report', save_fig_path=None, **kwargs):\n",
        "    fig, ax = plt.subplots(figsize=(8,5))    \n",
        "    clf_report = classification_report(y_true, y_pred, output_dict=True, **kwargs)\n",
        "    keys_to_plot = [key for key in clf_report.keys() if key not in ('accuracy', 'macro avg', 'weighted avg')]\n",
        "    df = pd.DataFrame(clf_report, columns=keys_to_plot).T\n",
        "    df.sort_values(by=['support'], inplace=True) \n",
        "    \n",
        "    rows, cols = df.shape\n",
        "    mask = np.zeros(df.shape)\n",
        "    mask[:,cols-1] = True\n",
        " \n",
        "    ax = sns.heatmap(df, mask=mask, annot=True, cmap=\"YlGn\", fmt='.3g', cbar=False,\n",
        "            vmin=0.0,\n",
        "            vmax=1.0,\n",
        "            linewidths=.4, linecolor='white'\n",
        "                    )\n",
        "    \n",
        "    mask = np.zeros(df.shape)\n",
        "    mask[:,:cols-1] = True    \n",
        "    \n",
        "    ax = sns.heatmap(df, mask=mask, annot=True, cmap=\"YlGn\", cbar=False,\n",
        "            linewidths=2, linecolor='white', fmt='.0f',\n",
        "            vmin=df['support'].min(),\n",
        "            vmax=df['support'].sum(),         \n",
        "            norm=mpl.colors.Normalize(vmin=df['support'].min(),\n",
        "                                      vmax=df['support'].sum())\n",
        "                    ) \n",
        "            \n",
        "    plt.title(title)\n",
        "    plt.yticks(np.arange(length)+.2, classes, rotation=90)\n",
        "         \n",
        "    if (save_fig_path != None):\n",
        "        path = pathlib.Path(save_fig_path)\n",
        "        path.parent.mkdir(parents=True, exist_ok=True)\n",
        "        fig.savefig(save_fig_path)\n",
        "    \n",
        "    return fig, ax\n",
        "\n",
        "fig, ax = plot_classification_report(y_true, y_pred, \n",
        "                    title='Classification Report',\n",
        "                    target_names=labels,\n",
        "                    save_fig_path = f'{file_path}/clf_report.png',)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Evaluation Pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f\"outputs/v1/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Predict On New Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Random Image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 76\n",
        "label = labels[1] # select 0 for 'healthy' or 1 for 'powdery_mildew'\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Convert Image To Array & Prepare for Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict Class Probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_proba = model.predict(my_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_proba < 0.5]\n",
        "\n",
        "if pred_class == target_map[1]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
