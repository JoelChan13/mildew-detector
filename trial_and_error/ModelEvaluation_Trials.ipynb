{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Model and Evaluation Trial and Errors**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "* Establish the best fits for the fulfilfement of the Business Requirements and Hypothesis Validation.\n",
    "\n",
    "## Inputs\n",
    "\n",
    "* inputs/cherryleaves_dataset/cherry-leaves/test\n",
    "* inputs/cherryleaves_dataset/cherry-leaves/train\n",
    "* inputs/cherryleaves_dataset/cherry-leaves/validation\n",
    "* image shape embeddings.\n",
    "\n",
    "```plaintext\n",
    "├── inputs\n",
    "│ └── cherryleaves_dataset\n",
    "│ └── cherry-leaves\n",
    "│   ├── test\n",
    "│   │ ├── healthy\n",
    "│   │ └── powdery_mildew\n",
    "│   ├── train\n",
    "│   │ ├── healthy\n",
    "│   │ └── powdery_mildew\n",
    "│   └── validation\n",
    "│   │ ├── healthy\n",
    "│   │ └── powdery_mildew\n",
    "└── ...\n",
    "``` \n",
    "\n",
    "## Outputs\n",
    "\n",
    "* Image distribution plot in train, validation, and test set\n",
    "* Image augementation\n",
    "* Class indices to change prediction inference in labels\n",
    "* Creation of ML model\n",
    "* Train ML model\n",
    "* Save ML model\n",
    "* Create Learning Curve Plot for model performance\n",
    "* Model Evaluation on pickle file\n",
    "* Prediction on the random image file\n",
    "\n",
    "## Additional Comments\n",
    "\n",
    "* Uncomment code which is relevant for the required tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "import tensorflow as tf\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Working Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspace/mildew-detector')\n",
    "print(\"You set a new current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = os.getcwd()\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Input Directories\n",
    "Set train, validation and test paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data_dir = 'inputs/cherryleaves_dataset/cherry-leaves'\n",
    "train_path = my_data_dir + '/train' \n",
    "val_path = my_data_dir + '/validation'\n",
    "test_path = my_data_dir + '/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 'alfa'\n",
    "file_path = f'outputs/{version}'\n",
    "\n",
    "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
    "    print('Old version is already available create a new version.')\n",
    "    pass\n",
    "else:\n",
    "    os.makedirs(name=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Label Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = os.listdir(train_path)\n",
    "print('Label for the images are', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Image Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import saved image shape embedding\n",
    "import joblib\n",
    "version = 'v1'\n",
    "\n",
    "# Set image shape for RGB - comment out if using rgb\n",
    "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
    "image_shape\n",
    "\n",
    "# ### SET NEW IMAGE SHAPE FOR GRAYSCALE - comment out if using grayscale\n",
    "# image_shape = (256, 256, 3)\n",
    "# image_shape\n",
    "# joblib.dump(value=image_shape ,\n",
    "#             filename=f\"{file_path}/image_shape_g.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Distribution "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Number of Images per Set & Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "df_freq = pd.DataFrame([])\n",
    "for folder in ['train', 'test', 'validation']:\n",
    "    for label in labels:\n",
    "        df_freq = df_freq.append(\n",
    "            pd.Series(data={'Set': folder,\n",
    "                            'Label': label,\n",
    "                            'Count': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))}\n",
    "                      ),\n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"* {folder} - {label}: {len(os.listdir(my_data_dir+'/'+ folder + '/' + label))} images\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "### Plotting the Data Using Seaborn and Matplotlib\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=df_freq, x='Set', y='Count', hue='Label')\n",
    "plt.savefig(f'{file_path}/labels_distribution.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Distribution - Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_freq, \n",
    "            x=\"Set\", \n",
    "            y=\"Count\", \n",
    "            color='Label', \n",
    "            title=\"Cherry Leaves Dataset\", \n",
    "            text_auto=True)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800, \n",
    "    height=500, \n",
    "    )\n",
    "fig.show()\n",
    "fig.write_image(f'outputs/{version}/number_leaves_sets.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Distribution - Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=df_freq, x='Set', y='Count', estimator=sum, ci=None)\n",
    "plt.title('Cherry leaves dataset distribution')\n",
    "plt.xlabel('Set')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig(f'{file_path}/sets_distribution_bar.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
    "                                          width_shift_range=0.10,\n",
    "                                          height_shift_range=0.10,\n",
    "                                          shear_range=0.1,\n",
    "                                          zoom_range=0.1,\n",
    "                                          horizontal_flip=True,\n",
    "                                          vertical_flip=True,\n",
    "                                          fill_mode='nearest',\n",
    "                                          rescale=1./255\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Training Image Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "                                                     target_size=image_shape[:2],\n",
    "                                                     color_mode='rgb',\n",
    "                                                     batch_size=batch_size,\n",
    "                                                     class_mode='categorical',\n",
    "                                                     shuffle=True\n",
    "                                                     )\n",
    "\n",
    "train_set.class_indices\n",
    "\n",
    "# ### Grayscale\n",
    "# train_set = augmented_image_data.flow_from_directory(train_path,\n",
    "#                                                      target_size=image_shape[:2],\n",
    "#                                                      color_mode='grayscale',\n",
    "#                                                      batch_size=batch_size,\n",
    "#                                                      class_mode='categorical',\n",
    "#                                                      shuffle=True\n",
    "#                                                      )\n",
    "\n",
    "# train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Training Image Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for _ in range(3):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    img, label = train_set.next()\n",
    "    print(img.shape)  \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "\n",
    "# ### Grayscale\n",
    "# for _ in range(3):\n",
    "#     plt.figure(figsize=(2, 2))\n",
    "#     img, label = train_set.next()\n",
    "#     print(img.shape)  \n",
    "#     plt.imshow(img[0], cmap='gray')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Validation Image Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Softmax RGB\n",
    "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "                                                                        target_size=image_shape[:2],\n",
    "                                                                        color_mode='rgb',\n",
    "                                                                        batch_size=batch_size,\n",
    "                                                                        class_mode='categorical',\n",
    "                                                                        shuffle=False\n",
    "                                                                        )\n",
    "\n",
    "validation_set.class_indices\n",
    "\n",
    "# ### Grayscale\n",
    "# validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "#                                                                         target_size=image_shape[:2],\n",
    "#                                                                         color_mode='grayscale',\n",
    "#                                                                         batch_size=batch_size,\n",
    "#                                                                         class_mode='categorical',\n",
    "#                                                                         shuffle=False\n",
    "#                                                                         )\n",
    "\n",
    "# validation_set.class_indices\n",
    "\n",
    "# ### Sigmoid\n",
    "# validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
    "#                                                                         target_size=image_shape[:2],\n",
    "#                                                                         color_mode='rgb',\n",
    "#                                                                         batch_size=batch_size,\n",
    "#                                                                         class_mode='binary',\n",
    "#                                                                         shuffle=False\n",
    "#                                                                         )\n",
    "\n",
    "# validation_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Validation Image Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### RGB\n",
    "for _ in range(3): # comment out if using grayscale\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    img, label = validation_set.next()\n",
    "    print(img.shape)  \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "\n",
    "# ### Grayscale\n",
    "# for _ in range(3): # comment out if using RGB\n",
    "#     plt.figure(figsize=(2, 2))\n",
    "#     img, label = validation_set.next()\n",
    "#     print(img.shape)\n",
    "#     plt.imshow(img[0], cmap='gray')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augment Test Image Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Softmax\n",
    "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "                                                                  target_size=image_shape[:2],\n",
    "                                                                  color_mode='rgb',\n",
    "                                                                  batch_size=batch_size,\n",
    "                                                                  class_mode='categorical',\n",
    "                                                                  shuffle=False\n",
    "                                                                  )\n",
    "\n",
    "test_set.class_indices\n",
    "\n",
    "# ### Grayscale\n",
    "# test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "#                                                                   target_size=image_shape[:2],\n",
    "#                                                                   color_mode='grayscale',\n",
    "#                                                                   batch_size=batch_size,\n",
    "#                                                                   class_mode='categorical',\n",
    "#                                                                   shuffle=False\n",
    "#                                                                   )\n",
    "\n",
    "# test_set.class_indices\n",
    "\n",
    "# ### Sigmoid\n",
    "# test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
    "#                                                                   target_size=image_shape[:2],\n",
    "#                                                                   color_mode='rgb',\n",
    "#                                                                   batch_size=batch_size,\n",
    "#                                                                   class_mode='binary',\n",
    "#                                                                   shuffle=False\n",
    "#                                                                   )\n",
    "\n",
    "# test_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Augmented Test Image Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(3):\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    img, label = test_set.next()\n",
    "    print(img.shape)  \n",
    "    plt.imshow(img[0])\n",
    "    plt.show()\n",
    "\n",
    "### Grayscale\n",
    "# for _ in range(3):\n",
    "#     plt.figure(figsize=(2, 2))\n",
    "#     img, label = test_set.next()\n",
    "#     print(img.shape)\n",
    "#     plt.imshow(img[0], cmap='gray')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=train_set.class_indices,\n",
    "            filename=f\"{file_path}/class_indices_softmax.pkl\")\n",
    "\n",
    "## Sigmoid\n",
    "# joblib.dump(value=train_set.class_indices,\n",
    "#             filename=f\"{file_path}/class_indices_sigmoid.pkl\")\n",
    "\n",
    "## Grayscale\n",
    "# joblib.dump(value=train_set.class_indices,\n",
    "#             filename=f\"{file_path}/class_indices_grayscale.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import models, layers, regularizers\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam, Adagrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Softmax\n",
    "def create_tf_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    ### input layer\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=image_shape, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    ### convolutional layers\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu')) # to comment out if trialing with one less convolution layer\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2))) # to comment out if trialing with one less convolution layer\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    ### fully connected layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(.2))\n",
    "\n",
    "    ### output\n",
    "    model.add(Dense(2, activation='softmax')) \n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer='adagrad', # to replace with other optimizers if trialing \n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# ### Sigmoid\n",
    "# def create_tf_model():\n",
    "#     model = Sequential()\n",
    "\n",
    "#     ### input layer\n",
    "#     model.add(Conv2D(32, (3, 3), input_shape=image_shape, activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     ### convolutional layers\n",
    "#     model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))      \n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "#     ### fully connected layer\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dropout(.2))\n",
    "\n",
    "#     ### output\n",
    "#     model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "#     model.compile(loss='binary_crossentropy', \n",
    "#                   optimizer='adagrad',\n",
    "#                   metrics=['accuracy'])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_tf_model().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_accuracy',mode='max',verbose=1, patience=2)\n",
    "m_checkpoint = ModelCheckpoint(filepath='outputs/v1/powdery_mildew_model.h5', monitor='val_accuracy', mode='max', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_tf_model()\n",
    "model.fit(train_set,\n",
    "          batch_size=batch_size,\n",
    "          epochs=32,\n",
    "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
    "          validation_data=validation_set,\n",
    "          callbacks=[early_stop, m_checkpoint], # comment out if removing early stop\n",
    "          verbose=1\n",
    "          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('outputs/alfa/powdery_mildew_model_softmax_early.h5')\n",
    "# model.save('outputs/alfa/powdery_mildew_model_softmax.h5') # uncomment if not using early stop\n",
    "# model.save('outputs/alfa/powdery_mildew_model_sigmoid_early.h5') # uncomment if using sigmoid with early stop\n",
    "# model.save('outputs/alfa/powdery_mildew_model_sigmoid.h5') # uncomment if using sigmoid without early stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation, Loss & Accuracy Over Multiple Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax with Early Stop\n",
    "losses = pd.DataFrame(model.history.history)\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.set_style(\"whitegrid\")\n",
    "losses[['loss', 'val_loss']].plot(style='.-')\n",
    "plt.title(\"Loss\")\n",
    "plt.savefig(f'{file_path}/model_training_losses_softmax_early.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "plt.title(\"Accuracy\")\n",
    "plt.savefig(f'{file_path}/model_training_acc_softmax_early.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# # Softmax without Early Stop\n",
    "# losses = pd.DataFrame(model.history.history)\n",
    "# plt.figure(figsize=(5, 4))\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# losses[['loss', 'val_loss']].plot(style='.-')\n",
    "# plt.title(\"Loss\")\n",
    "# plt.savefig(f'{file_path}/model_training_losses_softmax.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\n\")\n",
    "# losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.savefig(f'{file_path}/model_training_acc_softmax.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()\n",
    "\n",
    "# # Sigmoid with Early Stop\n",
    "# losses = pd.DataFrame(model.history.history)\n",
    "# plt.figure(figsize=(5, 4))\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# losses[['loss', 'val_loss']].plot(style='.-')\n",
    "# plt.title(\"Loss\")\n",
    "# plt.savefig(f'{file_path}/model_training_losses_sigmoid_early.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\n\")\n",
    "# losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.savefig(f'{file_path}/model_training_acc_sigmoid_early.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "\n",
    "# # Sigmoid without Early Stop\n",
    "# losses = pd.DataFrame(model.history.history)\n",
    "# plt.figure(figsize=(5, 4))\n",
    "# sns.set_style(\"whitegrid\")\n",
    "# losses[['loss', 'val_loss']].plot(style='.-')\n",
    "# plt.title(\"Loss\")\n",
    "# plt.savefig(f'{file_path}/model_training_losses_sigmoid.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\n\")\n",
    "# losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
    "# plt.title(\"Accuracy\")\n",
    "# plt.savefig(f'{file_path}/model_training_acc_sigmoid.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & Accuracy Over Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax with Early Stop\n",
    "pd.DataFrame(model.history.history).plot(figsize=(8,5))\n",
    "plt.savefig(f'{file_path}/model_loss_acc_softmax_early.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# # Softmax without Early Stop\n",
    "# pd.DataFrame(model.history.history).plot(figsize=(8,5))\n",
    "# plt.savefig(f'{file_path}/model_loss_acc_softmax.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()\n",
    "\n",
    "# # Sigmoid with Early Stop\n",
    "# pd.DataFrame(model.history.history).plot(figsize=(8,5))\n",
    "# plt.savefig(f'{file_path}/model_loss_acc_sigmoid_early.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()\n",
    "\n",
    "# # Softmax without Early Stop\n",
    "# pd.DataFrame(model.history.history).plot(figsize=(8,5))\n",
    "# plt.savefig(f'{file_path}/model_loss_acc_sigmoid.png',\n",
    "#             bbox_inches='tight', dpi=150)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & Validation for Loss & Accuracy Over Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter( y=model.history.history['val_loss'], name=\"val_loss\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter( y=model.history.history['loss'], name=\"loss\"),\n",
    "    secondary_y=False,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter( y=model.history.history['val_accuracy'], name=\"val accuracy\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "fig.add_trace(\n",
    "    go.Scatter( y=model.history.history['accuracy'], name=\"accuracy\"),\n",
    "    secondary_y=True,\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Loss/Accuracy of LSTM Model\"\n",
    ")\n",
    "\n",
    "fig.update_xaxes(title_text=\"Epoch\")\n",
    "\n",
    "fig.update_yaxes(title_text=\"<b>primary</b> Loss\", secondary_y=False)\n",
    "fig.update_yaxes(title_text=\"<b>secondary</b> Accuracy\", secondary_y=True)\n",
    "\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800, \n",
    "    height=500, \n",
    "    )\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(f'{file_path}/model_history_softmax_early.png')\n",
    "# fig.write_image(f'{file_path}/model_history_softmax.png') # uncomment to change for softmax without early stop\n",
    "# fig.write_image(f'{file_path}/model_history_sigmoid_early.png') # uncomment to change for sigmoid with early stop\n",
    "# fig.write_image(f'{file_path}/model_history_sigmoid.png') # uncomment to change for sigmoid without early stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('outputs/alfa/powdery_mildew_model_softmax_early.h5')\n",
    "# model = load_model('outputs/alfa/powdery_mildew_model_softmax.h5') # uncomment if not using early stop\n",
    "# model = load_model('outputs/alfa/powdery_mildew_model_sigmoid_early.h5') # uncomment if using sigmoid with early stop\n",
    "# model = load_model('outputs/alfa/powdery_mildew_model_sigmoid.h5') # uncomment if using sigmoid without early stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(test_set, batch_size=batch_size)\n",
    "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))\n",
    "print(\"Model Loss: \",evaluation[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Accuracy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set.reset()\n",
    "\n",
    "x_true, y_true = next(test_set)\n",
    "preds = np.argmax(model.predict(test_set), axis=1)\n",
    "y_pred = np.rint(preds)\n",
    "y_true = test_set.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, accuracy_score, roc_auc_score\n",
    "\n",
    "# Set the style of the plots using seaborn\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "# Compute the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "\n",
    "# Calculate the area under the ROC curve (AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Create a new figure for the ROC curve plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Set line width for the plot\n",
    "lw = 2\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "\n",
    "# Plot the diagonal line representing a random classifier\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, label=\"Random classifier\", linestyle='--')\n",
    "\n",
    "# Set the limits for the x and y axes\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Label the x and y axes\n",
    "plt.xlabel('False Positive Rate (Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "\n",
    "# Add a legend to the plot\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Save the figure to a file with specified path and properties\n",
    "plt.savefig(f'{file_path}/roccurve_softmax_early.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "# plt.savefig(f'{file_path}/roccurve_softmax.png',\n",
    "#             bbox_inches='tight', dpi=150) # uncomment for softmax without early stop\n",
    "# plt.savefig(f'{file_path}/roccurve_sigmoid_early.png',\n",
    "#             bbox_inches='tight', dpi=150) # uncomment for sigmoid with early stop\n",
    "# plt.savefig(f'{file_path}/roccurve_sigmoid.png',\n",
    "#             bbox_inches='tight', dpi=150) # uncomment for sigmoid without early stop\n",
    "print('Area Under ROC-Curve: ', roc_auc_score(y_true, y_pred))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Classification Report:\\n----------------------\\n')\n",
    "print(classification_report(y_true, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "# Retrieve the class labels from the test set\n",
    "classes=list(test_set.class_indices.keys()) \n",
    "length=len(classes)\n",
    "\n",
    "# Create a new figure for the confusion matrix plot\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "# Plot the confusion matrix using a heatmap\n",
    "sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "\n",
    "# Customize the x-axis and y-axis tick labels\n",
    "plt.xticks(np.arange(length)+.5, classes, rotation= 0, fontsize=8)\n",
    "plt.yticks(np.arange(length)+.3, classes, rotation=90, fontsize=8)\n",
    "\n",
    "# Label the x-axis and y-axis\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n",
    "# Set the title of the plot\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# Save the figure to a file with the specified path, ensuring tight bounding box and high resolution\n",
    "plt.savefig(f'{file_path}/confusion_matrix_softmax_early.png',\n",
    "            bbox_inches='tight', dpi=150)\n",
    "# plt.savefig(f'{file_path}/confusion_matrix_softmax.png',\n",
    "#             bbox_inches='tight', dpi=150) # uncomment for softmax without early stop\n",
    "# plt.savefig(f'{file_path}/confusion_matrix_sigmoid_early.png',\n",
    "#             bbox_inches='tight', dpi=150) # uncomment for sigmoid with early stop\n",
    "# plt.savefig(f'{file_path}/confusion_matrix_sigmoid.png',\n",
    "#             bbox_inches='tight', dpi=150) # uncomment for sigmoid without early stop\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Evaluation Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=evaluation,\n",
    "            filename=f\"outputs/alfa/evaluation.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict On New Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Random Image as PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "pointer = 61\n",
    "label = labels[1] # select 0 for 'healthy' or 1 for 'powdery_mildew'\n",
    "\n",
    "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
    "                           target_size=image_shape, color_mode='rgb')\n",
    "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "pil_image\n",
    "\n",
    "# ### Grayscale\n",
    "# from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# pointer = 32\n",
    "# label = labels[1]  # select healthy or powdery_mildew\n",
    "\n",
    "# pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
    "#                            target_size=(256, 256, 1), color_mode='grayscale')\n",
    "# print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
    "# pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Image to Array & Prepare for Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_image = image.img_to_array(pil_image)\n",
    "my_image = np.expand_dims(my_image, axis=0)/255\n",
    "print(my_image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Class Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_proba = model.predict(my_image)[0, 0]\n",
    "\n",
    "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
    "pred_class = target_map[pred_proba < 0.5]\n",
    "\n",
    "if pred_class == target_map[1]:\n",
    "    pred_proba = 1 - pred_proba\n",
    "\n",
    "print(f\"{pred_class} {round(pred_proba*100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
